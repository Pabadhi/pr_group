{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":15444,"sourceType":"datasetVersion","datasetId":11102}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-03T12:39:44.017934Z","iopub.execute_input":"2023-12-03T12:39:44.018961Z","iopub.status.idle":"2023-12-03T12:39:44.037241Z","shell.execute_reply.started":"2023-12-03T12:39:44.018913Z","shell.execute_reply":"2023-12-03T12:39:44.036252Z"},"trusted":true},"execution_count":184,"outputs":[{"name":"stdout","text":"/kaggle/input/cifar10-python/cifar-10-python.tar.gz\n/kaggle/input/cifar10-python/cifar-10-batches-py/data_batch_1\n/kaggle/input/cifar10-python/cifar-10-batches-py/data_batch_2\n/kaggle/input/cifar10-python/cifar-10-batches-py/batches.meta\n/kaggle/input/cifar10-python/cifar-10-batches-py/test_batch\n/kaggle/input/cifar10-python/cifar-10-batches-py/data_batch_3\n/kaggle/input/cifar10-python/cifar-10-batches-py/data_batch_5\n/kaggle/input/cifar10-python/cifar-10-batches-py/data_batch_4\n/kaggle/input/cifar10-python/cifar-10-batches-py/readme.html\n","output_type":"stream"}]},{"cell_type":"code","source":"import keras\nfrom keras.datasets import cifar10\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n\nx_train = x_train.astype('float32') / 255.0\nx_test = x_test.astype('float32') / 255.0\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T12:39:56.348179Z","iopub.execute_input":"2023-12-03T12:39:56.349046Z","iopub.status.idle":"2023-12-03T12:39:57.371788Z","shell.execute_reply.started":"2023-12-03T12:39:56.349010Z","shell.execute_reply":"2023-12-03T12:39:57.370796Z"},"trusted":true},"execution_count":185,"outputs":[]},{"cell_type":"code","source":"print(\"Input image shape:\", x_train.shape[1:])","metadata":{"execution":{"iopub.status.busy":"2023-12-03T11:40:55.497413Z","iopub.execute_input":"2023-12-03T11:40:55.497867Z","iopub.status.idle":"2023-12-03T11:40:55.503480Z","shell.execute_reply.started":"2023-12-03T11:40:55.497835Z","shell.execute_reply":"2023-12-03T11:40:55.502350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler()\nx_train = scaler.fit_transform(x_train.reshape(-1, 32 * 32 * 3)).reshape(-1, 32, 32, 3)\nx_val = scaler.transform(x_val.reshape(-1, 32 * 32 * 3)).reshape(-1, 32, 32, 3)\nx_test = scaler.transform(x_test.reshape(-1, 32 * 32 * 3)).reshape(-1, 32, 32, 3)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T12:40:02.862596Z","iopub.execute_input":"2023-12-03T12:40:02.863551Z","iopub.status.idle":"2023-12-03T12:40:05.416890Z","shell.execute_reply.started":"2023-12-03T12:40:02.863518Z","shell.execute_reply":"2023-12-03T12:40:05.415881Z"},"trusted":true},"execution_count":186,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\ndef create_model():\n    m1=3\n    m2=3\n    x1=64\n    x2=32\n    d=0.2\n    x3=4096\n\n    model = Sequential()\n\n    model.add(Conv2D(filters=x1, kernel_size=(m1, m1), activation='relu', input_shape=(32, 32, 3),padding=\"same\"))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(filters=x2, kernel_size=(m2, m2), activation='relu',padding=\"same\"))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.3))\n\n    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu',padding=\"same\"))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.4))\n\n    model.add(Flatten())\n\n    model.add(Dense(x3, activation='relu'))\n    model.add(Dropout(0.2))\n\n    model.add(Dense(10, activation='softmax'))\n    return model\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T10:18:59.392682Z","iopub.execute_input":"2023-12-03T10:18:59.393415Z","iopub.status.idle":"2023-12-03T10:18:59.403350Z","shell.execute_reply.started":"2023-12-03T10:18:59.393378Z","shell.execute_reply":"2023-12-03T10:18:59.402331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom keras.callbacks import ModelCheckpoint\nlearning_rate = 0.001\noptimizer = keras.optimizers.Adam(learning_rate=learning_rate)\nmodel=create_model();\nmodel.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nepochs = 20\ncheckpoint = ModelCheckpoint(\"best_model.h5\",  monitor='val_loss', save_best_only=True, mode='min' )","metadata":{"execution":{"iopub.status.busy":"2023-12-03T10:00:24.372545Z","iopub.execute_input":"2023-12-03T10:00:24.372914Z","iopub.status.idle":"2023-12-03T10:00:24.386246Z","shell.execute_reply.started":"2023-12-03T10:00:24.372888Z","shell.execute_reply":"2023-12-03T10:00:24.385388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x_train, y_train, epochs=epochs,validation_data=(x_val, y_val),callbacks=[checkpoint])","metadata":{"execution":{"iopub.status.busy":"2023-12-03T10:00:28.223340Z","iopub.execute_input":"2023-12-03T10:00:28.223683Z","iopub.status.idle":"2023-12-03T10:01:52.104567Z","shell.execute_reply.started":"2023-12-03T10:00:28.223658Z","shell.execute_reply":"2023-12-03T10:01:52.103635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-03T10:01:58.152311Z","iopub.execute_input":"2023-12-03T10:01:58.153079Z","iopub.status.idle":"2023-12-03T10:01:58.423676Z","shell.execute_reply.started":"2023-12-03T10:01:58.153043Z","shell.execute_reply":"2023-12-03T10:01:58.422798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rates = [0.0001, 0.001, 0.01, 0.1]\nepochs = 20\nhistory_dict = {}\n\nfor lr in learning_rates:\n    model=create_model()\n    learning_rate =lr\n    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    checkpoint = ModelCheckpoint(f\"best_model_lr_{lr}.h5\", monitor='val_loss', save_best_only=True, mode='min')\n    history = model.fit(x_train, y_train, epochs=epochs, validation_data=(x_val, y_val),callbacks=[checkpoint])\n    history_dict[lr] = history\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T10:19:19.067635Z","iopub.execute_input":"2023-12-03T10:19:19.068024Z","iopub.status.idle":"2023-12-03T10:27:48.020274Z","shell.execute_reply.started":"2023-12-03T10:19:19.067993Z","shell.execute_reply":"2023-12-03T10:27:48.019296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, (lr, history) in enumerate(history_dict.items(), 1):\n    plt.figure(figsize=(8, 6))\n\n    plt.plot(history.history['loss'], label=f'Training Loss (LR={lr})')\n    plt.plot(history.history['val_loss'], label=f'Validation Loss (LR={lr})')\n\n    plt.title(f'Training and Validation Loss for LR={lr}')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-03T11:15:14.474724Z","iopub.execute_input":"2023-12-03T11:15:14.475539Z","iopub.status.idle":"2023-12-03T11:15:15.727068Z","shell.execute_reply.started":"2023-12-03T11:15:14.475506Z","shell.execute_reply":"2023-12-03T11:15:15.726100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y_train[1])","metadata":{"execution":{"iopub.status.busy":"2023-12-03T11:18:20.742332Z","iopub.execute_input":"2023-12-03T11:18:20.742738Z","iopub.status.idle":"2023-12-03T11:18:20.748154Z","shell.execute_reply.started":"2023-12-03T11:18:20.742709Z","shell.execute_reply":"2023-12-03T11:18:20.747187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T11:18:26.886591Z","iopub.execute_input":"2023-12-03T11:18:26.886962Z","iopub.status.idle":"2023-12-03T11:18:26.891736Z","shell.execute_reply.started":"2023-12-03T11:18:26.886925Z","shell.execute_reply":"2023-12-03T11:18:26.890763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = \"/kaggle/working/best_model_lr_0.001.h5\"\nmodel = load_model(model_path)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T11:19:51.357549Z","iopub.execute_input":"2023-12-03T11:19:51.358459Z","iopub.status.idle":"2023-12-03T11:19:51.963848Z","shell.execute_reply.started":"2023-12-03T11:19:51.358423Z","shell.execute_reply":"2023-12-03T11:19:51.963056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(x_test)\ny_pred_classes = np.argmax(y_pred, axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T11:19:56.156623Z","iopub.execute_input":"2023-12-03T11:19:56.157522Z","iopub.status.idle":"2023-12-03T11:19:57.189870Z","shell.execute_reply.started":"2023-12-03T11:19:56.157487Z","shell.execute_reply":"2023-12-03T11:19:57.188861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate accuracy\ntest_accuracy = accuracy_score(y_test, y_pred_classes)\nprint(f'Test Accuracy: {test_accuracy}')\n\n# confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred_classes)\nprint('Confusion Matrix:')\nprint(conf_matrix)\n\n# precision and recall\nprecision = precision_score(y_test, y_pred_classes, average='weighted')\nrecall = recall_score(y_test, y_pred_classes, average='weighted')\n\nprint(f'Precision: {precision}')\nprint(f'Recall: {recall}')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T11:20:05.077002Z","iopub.execute_input":"2023-12-03T11:20:05.077709Z","iopub.status.idle":"2023-12-03T11:20:05.103539Z","shell.execute_reply.started":"2023-12-03T11:20:05.077675Z","shell.execute_reply":"2023-12-03T11:20:05.102351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom keras.applications import ResNet50\nfrom keras.models import Sequential\n\n# Load pre-trained ResNet50 model\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n\n# Freeze layers in the base model\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Create a fine-tuned model\ndef transfer_learning():\n    model = Sequential()\n    model.add(base_model)\n    model.add(Flatten())\n    model.add(Dense(4096, activation='relu'))\n    model.add(Dropout(0.15))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(10, activation='softmax'))\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-12-03T12:50:44.382952Z","iopub.execute_input":"2023-12-03T12:50:44.383317Z","iopub.status.idle":"2023-12-03T12:51:36.773509Z","shell.execute_reply.started":"2023-12-03T12:50:44.383290Z","shell.execute_reply":"2023-12-03T12:51:36.772457Z"},"trusted":true},"execution_count":191,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rates = [0.0015]\nepochs = 20\nhistory1_dict = {}\n\nfor lr in learning_rates:\n    model=transfer_learning()\n    learning_rate =lr\n    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    checkpoint = ModelCheckpoint(f\"best_model_lr_transfer{lr}.h5\", monitor='val_loss', save_best_only=True, mode='min')\n    history1 = model.fit(x_train, y_train, epochs=epochs, validation_data=(x_val, y_val),callbacks=[checkpoint], batch_size=200)\n    history1_dict[lr] = history1","metadata":{"execution":{"iopub.status.busy":"2023-12-03T12:58:21.943172Z","iopub.execute_input":"2023-12-03T12:58:21.943909Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/20\n200/200 [==============================] - 10s 33ms/step - loss: 2.0883 - accuracy: 0.2615 - val_loss: 1.8174 - val_accuracy: 0.3396\nEpoch 2/20\n200/200 [==============================] - 5s 27ms/step - loss: 1.7273 - accuracy: 0.3775 - val_loss: 1.6592 - val_accuracy: 0.3981\nEpoch 3/20\n200/200 [==============================] - 5s 26ms/step - loss: 1.6398 - accuracy: 0.4140 - val_loss: 1.6127 - val_accuracy: 0.4226\nEpoch 4/20\n200/200 [==============================] - 5s 27ms/step - loss: 1.5945 - accuracy: 0.4294 - val_loss: 1.5596 - val_accuracy: 0.4420\nEpoch 5/20\n200/200 [==============================] - 5s 23ms/step - loss: 1.5665 - accuracy: 0.4403 - val_loss: 1.5880 - val_accuracy: 0.4369\nEpoch 6/20\n200/200 [==============================] - 5s 27ms/step - loss: 1.5379 - accuracy: 0.4540 - val_loss: 1.5416 - val_accuracy: 0.4496\nEpoch 7/20\n200/200 [==============================] - 6s 28ms/step - loss: 1.5131 - accuracy: 0.4595 - val_loss: 1.5402 - val_accuracy: 0.4580\nEpoch 8/20\n200/200 [==============================] - 5s 27ms/step - loss: 1.4845 - accuracy: 0.4719 - val_loss: 1.5301 - val_accuracy: 0.4691\nEpoch 9/20\n200/200 [==============================] - 5s 27ms/step - loss: 1.4723 - accuracy: 0.4784 - val_loss: 1.5080 - val_accuracy: 0.4667\nEpoch 10/20\n200/200 [==============================] - 5s 23ms/step - loss: 1.4415 - accuracy: 0.4899 - val_loss: 1.5338 - val_accuracy: 0.4591\nEpoch 11/20\n200/200 [==============================] - 5s 27ms/step - loss: 1.4245 - accuracy: 0.4958 - val_loss: 1.4954 - val_accuracy: 0.4735\nEpoch 12/20\n200/200 [==============================] - 5s 23ms/step - loss: 1.4077 - accuracy: 0.5032 - val_loss: 1.5064 - val_accuracy: 0.4728\nEpoch 13/20\n200/200 [==============================] - 5s 23ms/step - loss: 1.3960 - accuracy: 0.5053 - val_loss: 1.5737 - val_accuracy: 0.4478\nEpoch 14/20\n127/200 [==================>...........] - ETA: 1s - loss: 1.3706 - accuracy: 0.5165","output_type":"stream"}]},{"cell_type":"code","source":"for i, (lr, history1) in enumerate(history1_dict.items(), 1):\n    plt.figure(figsize=(8, 6))\n\n    plt.plot(history1.history['loss'], label=f'Training Loss (LR={lr})')\n    plt.plot(history1.history['val_loss'], label=f'Validation Loss (LR={lr})')\n\n    plt.title(f'Training and Validation Loss for LR={lr}')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]}]}